{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66e0e91",
   "metadata": {},
   "source": [
    "Nutritional Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d904da",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681b45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c4e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableExtractor:\n",
    "\n",
    "    def __init__(self, image_path):\n",
    "        self.image_path = image_path\n",
    "\n",
    "    def execute(self):\n",
    "        self.read_image()\n",
    "        self.store_process_image(\"0_original.jpg\", self.image)\n",
    "        self.convert_image_to_grayscale()\n",
    "        self.store_process_image(\"1_grayscaled.jpg\", self.grayscale_image)\n",
    "        self.threshold_image()\n",
    "        self.store_process_image(\"3_thresholded.jpg\", self.thresholded_image)\n",
    "        self.invert_image()\n",
    "        self.store_process_image(\"4_inverteded.jpg\", self.inverted_image)\n",
    "        self.dilate_image()\n",
    "        self.store_process_image(\"5_dialateded.jpg\", self.dilated_image)\n",
    "        self.find_contours()\n",
    "        self.store_process_image(\"6_all_contours.jpg\", self.image_with_all_contours)\n",
    "        self.filter_contours_and_leave_only_rectangles()\n",
    "        self.store_process_image(\"7_only_rectangular_contours.jpg\", self.image_with_only_rectangular_contours)\n",
    "        self.find_largest_contour_by_area()\n",
    "        self.store_process_image(\"8_contour_with_max_area.jpg\", self.image_with_contour_with_max_area)\n",
    "        self.order_points_in_the_contour_with_max_area()\n",
    "        self.store_process_image(\"9_with_4_corner_points_plotted.jpg\", self.image_with_points_plotted)\n",
    "        self.calculate_new_width_and_height_of_image()\n",
    "        self.apply_perspective_transform()\n",
    "        self.store_process_image(\"10_perspective_corrected.jpg\", self.perspective_corrected_image)\n",
    "        self.add_10_percent_padding()\n",
    "        self.store_process_image(\"11_perspective_corrected_with_padding.jpg\", self.perspective_corrected_image_with_padding)\n",
    "        return self.perspective_corrected_image_with_padding\n",
    "\n",
    "    def read_image(self):\n",
    "        self.image = cv2.imread(self.image_path)\n",
    "\n",
    "    def convert_image_to_grayscale(self):\n",
    "        self.grayscale_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def blur_image(self):\n",
    "        self.blurred_image = cv2.blur(self.grayscale_image, (5, 5))\n",
    "\n",
    "    def threshold_image(self):\n",
    "        self.thresholded_image = cv2.threshold(self.grayscale_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    def invert_image(self):\n",
    "        self.inverted_image = cv2.bitwise_not(self.thresholded_image)\n",
    "\n",
    "    def dilate_image(self):\n",
    "        self.dilated_image = cv2.dilate(self.inverted_image, None, iterations=5)\n",
    "\n",
    "    def find_contours(self):\n",
    "        self.contours, self.hierarchy = cv2.findContours(self.dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        self.image_with_all_contours = self.image.copy()\n",
    "        cv2.drawContours(self.image_with_all_contours, self.contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "    def filter_contours_and_leave_only_rectangles(self):\n",
    "        self.rectangular_contours = []\n",
    "        for contour in self.contours:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "            if len(approx) == 4:\n",
    "                self.rectangular_contours.append(approx)\n",
    "        self.image_with_only_rectangular_contours = self.image.copy()\n",
    "        cv2.drawContours(self.image_with_only_rectangular_contours, self.rectangular_contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "    def find_largest_contour_by_area(self):\n",
    "        max_area = 0\n",
    "        self.contour_with_max_area = None\n",
    "        for contour in self.rectangular_contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                self.contour_with_max_area = contour\n",
    "        self.image_with_contour_with_max_area = self.image.copy()\n",
    "        cv2.drawContours(self.image_with_contour_with_max_area, [self.contour_with_max_area], -1, (0, 255, 0), 3)\n",
    "\n",
    "    def order_points_in_the_contour_with_max_area(self):\n",
    "        self.contour_with_max_area_ordered = self.order_points(self.contour_with_max_area)\n",
    "        self.image_with_points_plotted = self.image.copy()\n",
    "        for point in self.contour_with_max_area_ordered:\n",
    "            point_coordinates = (int(point[0]), int(point[1]))\n",
    "            self.image_with_points_plotted = cv2.circle(self.image_with_points_plotted, point_coordinates, 10, (0, 0, 255), -1)\n",
    "\n",
    "    def calculate_new_width_and_height_of_image(self):\n",
    "        existing_image_width = self.image.shape[1]\n",
    "        existing_image_width_reduced_by_10_percent = int(existing_image_width * 0.9)\n",
    "        \n",
    "        distance_between_top_left_and_top_right = self.calculateDistanceBetween2Points(self.contour_with_max_area_ordered[0], self.contour_with_max_area_ordered[1])\n",
    "        distance_between_top_left_and_bottom_left = self.calculateDistanceBetween2Points(self.contour_with_max_area_ordered[0], self.contour_with_max_area_ordered[3])\n",
    "\n",
    "        aspect_ratio = distance_between_top_left_and_bottom_left / distance_between_top_left_and_top_right\n",
    "\n",
    "        self.new_image_width = existing_image_width_reduced_by_10_percent\n",
    "        self.new_image_height = int(self.new_image_width * aspect_ratio)\n",
    "\n",
    "    def apply_perspective_transform(self):\n",
    "        pts1 = np.float32(self.contour_with_max_area_ordered)\n",
    "        pts2 = np.float32([[0, 0], [self.new_image_width, 0], [self.new_image_width, self.new_image_height], [0, self.new_image_height]])\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        self.perspective_corrected_image = cv2.warpPerspective(self.image, matrix, (self.new_image_width, self.new_image_height))\n",
    "\n",
    "    def add_10_percent_padding(self):\n",
    "        image_height = self.image.shape[0]\n",
    "        padding = int(image_height * 0.1)\n",
    "        self.perspective_corrected_image_with_padding = cv2.copyMakeBorder(self.perspective_corrected_image, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "\n",
    "    def draw_contours(self):\n",
    "        self.image_with_contours = self.image.copy()\n",
    "        cv2.drawContours(self.image_with_contours,  [ self.contour_with_max_area ], -1, (0, 255, 0), 1)\n",
    "\n",
    "    def calculateDistanceBetween2Points(self, p1, p2):\n",
    "        dis = ((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2) ** 0.5\n",
    "        return dis\n",
    "    \n",
    "    def order_points(self, pts):\n",
    "        # initialzie a list of coordinates that will be ordered\n",
    "        # such that the first entry in the list is the top-left,\n",
    "        # the second entry is the top-right, the third is the\n",
    "        # bottom-right, and the fourth is the bottom-left\n",
    "        pts = pts.reshape(4, 2)\n",
    "        rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "        # the top-left point will have the smallest sum, whereas\n",
    "        # the bottom-right point will have the largest sum\n",
    "        s = pts.sum(axis=1)\n",
    "        rect[0] = pts[np.argmin(s)]\n",
    "        rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "        # now, compute the difference between the points, the\n",
    "        # top-right point will have the smallest difference,\n",
    "        # whereas the bottom-left will have the largest difference\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        rect[1] = pts[np.argmin(diff)]\n",
    "        rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "        # return the ordered coordinates\n",
    "        return rect\n",
    "    \n",
    "    def store_process_image(self, file_name, image):\n",
    "        path = \"./process_images/table_extractor/\" + file_name\n",
    "        cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f525807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TableExtractor as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ca5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = \"/Users/ankitasarkar/Documents/LnT Internship/02. Works/03. Project_1_PDF_Extraction/03. Codes/ocr-extract-table-from-image-python-main/01. image/nutrition_table.jpg\"\n",
    "table_extractor = te.TableExtractor(path_to_image)\n",
    "perspective_corrected_image = table_extractor.execute()\n",
    "cv2.imshow(\"perspective_corrected_image\", perspective_corrected_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3667e1",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c316c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5e0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableLinesRemover:\n",
    "\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "\n",
    "    def execute(self):\n",
    "        self.grayscale_image()\n",
    "        self.store_process_image(\"0_grayscaled.jpg\", self.grey)\n",
    "        self.threshold_image()\n",
    "        self.store_process_image(\"1_thresholded.jpg\", self.thresholded_image)\n",
    "        self.invert_image()\n",
    "        self.store_process_image(\"2_inverted.jpg\", self.inverted_image)\n",
    "        self.erode_vertical_lines()\n",
    "        self.store_process_image(\"3_erode_vertical_lines.jpg\", self.vertical_lines_eroded_image)\n",
    "        self.erode_horizontal_lines()\n",
    "        self.store_process_image(\"4_erode_horizontal_lines.jpg\", self.horizontal_lines_eroded_image)\n",
    "        self.combine_eroded_images()\n",
    "        self.store_process_image(\"5_combined_eroded_images.jpg\", self.combined_image)\n",
    "        self.dilate_combined_image_to_make_lines_thicker()\n",
    "        self.store_process_image(\"6_dilated_combined_image.jpg\", self.combined_image_dilated)\n",
    "        self.subtract_combined_and_dilated_image_from_original_image()\n",
    "        self.store_process_image(\"7_image_without_lines.jpg\", self.image_without_lines)\n",
    "        self.remove_noise_with_erode_and_dilate()\n",
    "        self.store_process_image(\"8_image_without_lines_noise_removed.jpg\", self.image_without_lines_noise_removed)\n",
    "        return self.image_without_lines_noise_removed\n",
    "\n",
    "    def grayscale_image(self):\n",
    "        self.grey = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    def threshold_image(self):\n",
    "        self.thresholded_image = cv2.threshold(self.grey, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    def invert_image(self):\n",
    "        self.inverted_image = cv2.bitwise_not(self.thresholded_image)\n",
    "\n",
    "    def erode_vertical_lines(self):\n",
    "        hor = np.array([[1,1,1,1,1,1]])\n",
    "        self.vertical_lines_eroded_image = cv2.erode(self.inverted_image, hor, iterations=10)\n",
    "        self.vertical_lines_eroded_image = cv2.dilate(self.vertical_lines_eroded_image, hor, iterations=10)\n",
    "\n",
    "    def erode_horizontal_lines(self):\n",
    "        ver = np.array([[1],\n",
    "               [1],\n",
    "               [1],\n",
    "               [1],\n",
    "               [1],\n",
    "               [1],\n",
    "               [1]])\n",
    "        self.horizontal_lines_eroded_image = cv2.erode(self.inverted_image, ver, iterations=10)\n",
    "        self.horizontal_lines_eroded_image = cv2.dilate(self.horizontal_lines_eroded_image, ver, iterations=10)\n",
    "\n",
    "    def combine_eroded_images(self):\n",
    "        self.combined_image = cv2.add(self.vertical_lines_eroded_image, self.horizontal_lines_eroded_image)\n",
    "\n",
    "    def dilate_combined_image_to_make_lines_thicker(self):\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        self.combined_image_dilated = cv2.dilate(self.combined_image, kernel, iterations=5)\n",
    "\n",
    "    def subtract_combined_and_dilated_image_from_original_image(self):\n",
    "        self.image_without_lines = cv2.subtract(self.inverted_image, self.combined_image_dilated)\n",
    "\n",
    "    def remove_noise_with_erode_and_dilate(self):\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "        self.image_without_lines_noise_removed = cv2.erode(self.image_without_lines, kernel, iterations=1)\n",
    "        self.image_without_lines_noise_removed = cv2.dilate(self.image_without_lines_noise_removed, kernel, iterations=1)\n",
    "\n",
    "    def store_process_image(self, file_name, image):\n",
    "        path = \"./process_images/table_lines_remover/\" + file_name\n",
    "        cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23076cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TableLinesRemover as tlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231690a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_remover = tlr.TableLinesRemover(perspective_corrected_image)\n",
    "image_without_lines = lines_remover.execute()\n",
    "cv2.imshow(\"image_without_lines\", image_without_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd508e",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0526b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68e1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OcrToTableTool:\n",
    "\n",
    "    def __init__(self, image, original_image):\n",
    "        self.thresholded_image = image\n",
    "        self.original_image = original_image\n",
    "\n",
    "    def execute(self):\n",
    "        self.dilate_image()\n",
    "        self.store_process_image('0_dilated_image.jpg', self.dilated_image)\n",
    "        self.find_contours()\n",
    "        self.store_process_image('1_contours.jpg', self.image_with_contours_drawn)\n",
    "        self.convert_contours_to_bounding_boxes()\n",
    "        self.store_process_image('2_bounding_boxes.jpg', self.image_with_all_bounding_boxes)\n",
    "        self.mean_height = self.get_mean_height_of_bounding_boxes()\n",
    "        self.sort_bounding_boxes_by_y_coordinate()\n",
    "        self.club_all_bounding_boxes_by_similar_y_coordinates_into_rows()\n",
    "        self.sort_all_rows_by_x_coordinate()\n",
    "        self.crop_each_bounding_box_and_ocr()\n",
    "        self.generate_csv_file()\n",
    "\n",
    "    def threshold_image(self):\n",
    "        return cv2.threshold(self.grey_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    def convert_image_to_grayscale(self):\n",
    "        return cv2.cvtColor(self.image, self.dilated_image)\n",
    "\n",
    "    def dilate_image(self):\n",
    "        kernel_to_remove_gaps_between_words = np.array([\n",
    "                [1,1,1,1,1,1,1,1,1,1],\n",
    "               [1,1,1,1,1,1,1,1,1,1]\n",
    "        ])\n",
    "        self.dilated_image = cv2.dilate(self.thresholded_image, kernel_to_remove_gaps_between_words, iterations=5)\n",
    "        simple_kernel = np.ones((5,5), np.uint8)\n",
    "        self.dilated_image = cv2.dilate(self.dilated_image, simple_kernel, iterations=2)\n",
    "    \n",
    "    def find_contours(self):\n",
    "        result = cv2.findContours(self.dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        self.contours = result[0]\n",
    "        self.image_with_contours_drawn = self.original_image.copy()\n",
    "        cv2.drawContours(self.image_with_contours_drawn, self.contours, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    def approximate_contours(self):\n",
    "        self.approximated_contours = []\n",
    "        for contour in self.contours:\n",
    "            approx = cv2.approxPolyDP(contour, 3, True)\n",
    "            self.approximated_contours.append(approx)\n",
    "\n",
    "    def draw_contours(self):\n",
    "        self.image_with_contours = self.original_image.copy()\n",
    "        cv2.drawContours(self.image_with_contours, self.approximated_contours, -1, (0, 255, 0), 5)\n",
    "\n",
    "    def convert_contours_to_bounding_boxes(self):\n",
    "        self.bounding_boxes = []\n",
    "        self.image_with_all_bounding_boxes = self.original_image.copy()\n",
    "        for contour in self.contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            self.bounding_boxes.append((x, y, w, h))\n",
    "            self.image_with_all_bounding_boxes = cv2.rectangle(self.image_with_all_bounding_boxes, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "\n",
    "    def get_mean_height_of_bounding_boxes(self):\n",
    "        heights = []\n",
    "        for bounding_box in self.bounding_boxes:\n",
    "            x, y, w, h = bounding_box\n",
    "            heights.append(h)\n",
    "        return np.mean(heights)\n",
    "\n",
    "    def sort_bounding_boxes_by_y_coordinate(self):\n",
    "        self.bounding_boxes = sorted(self.bounding_boxes, key=lambda x: x[1])\n",
    "\n",
    "    def club_all_bounding_boxes_by_similar_y_coordinates_into_rows(self):\n",
    "        self.rows = []\n",
    "        half_of_mean_height = self.mean_height / 2\n",
    "        current_row = [ self.bounding_boxes[0] ]\n",
    "        for bounding_box in self.bounding_boxes[1:]:\n",
    "            current_bounding_box_y = bounding_box[1]\n",
    "            previous_bounding_box_y = current_row[-1][1]\n",
    "            distance_between_bounding_boxes = abs(current_bounding_box_y - previous_bounding_box_y)\n",
    "            if distance_between_bounding_boxes <= half_of_mean_height:\n",
    "                current_row.append(bounding_box)\n",
    "            else:\n",
    "                self.rows.append(current_row)\n",
    "                current_row = [ bounding_box ]\n",
    "        self.rows.append(current_row)\n",
    "\n",
    "    def sort_all_rows_by_x_coordinate(self):\n",
    "        for row in self.rows:\n",
    "            row.sort(key=lambda x: x[0])\n",
    "\n",
    "    def crop_each_bounding_box_and_ocr(self):\n",
    "        self.table = []\n",
    "        current_row = []\n",
    "        image_number = 0\n",
    "        for row in self.rows:\n",
    "            for bounding_box in row:\n",
    "                x, y, w, h = bounding_box\n",
    "                y = y - 5\n",
    "                cropped_image = self.original_image[y:y+h, x:x+w]\n",
    "                image_slice_path = \"./ocr_slices/img_\" + str(image_number) + \".jpg\"\n",
    "                cv2.imwrite(image_slice_path, cropped_image)\n",
    "                results_from_ocr = self.get_result_from_tersseract(image_slice_path)\n",
    "                current_row.append(results_from_ocr)\n",
    "                image_number += 1\n",
    "            self.table.append(current_row)\n",
    "            current_row = []\n",
    "\n",
    "    def get_result_from_tersseract(self, image_path):\n",
    "        output = subprocess.getoutput('tesseract ' + image_path + ' - -l eng --oem 3 --psm 7 --dpi 72 -c tessedit_char_whitelist=\"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789().calmg* \"')\n",
    "        output = output.strip()\n",
    "        return output\n",
    "\n",
    " \n",
    "    def generate_csv_file(self):\n",
    "        with open(\"output.csv\", \"w\") as f:\n",
    "            for row in self.table:\n",
    "                f.write(\",\".join(row) + \"\\n\")\n",
    "\n",
    "    def store_process_image(self, file_name, image):\n",
    "        path = \"./process_images/ocr_table_tool/\" + file_name\n",
    "        cv2.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f047f7d",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89644122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OcrToTableTool as ottt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b9dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_tool = ottt.OcrToTableTool(image_without_lines, perspective_corrected_image)\n",
    "ocr_tool.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0de805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51950757",
   "metadata": {},
   "source": [
    "## Step 5 - Merged Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cfa88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "processed_lines = []\n",
    "for idx, line in enumerate(lines):\n",
    "    columns = line.strip().split(',')\n",
    "    if len(columns) == 1:  # Check if the line has only one column\n",
    "        processed_line = ','.join([columns[0], columns[0]])  # Duplicate the column content\n",
    "        processed_lines.append(processed_line)\n",
    "    else:\n",
    "        processed_lines.append(line.strip())\n",
    "\n",
    "with open('output_02.csv', 'w') as file:\n",
    "    file.write('\\n'.join(processed_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d6c73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file converted to Excel.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file without headers\n",
    "df = pd.read_csv(\"output_02.csv\", header=None)\n",
    "\n",
    "# Reorder the columns\n",
    "df = df[[0, 1]]  # Select the 0th and 1st columns in this order\n",
    "\n",
    "# Save the result as an Excel file\n",
    "df.to_excel(\"output_02.xlsx\", index=False)\n",
    "\n",
    "print(\"CSV file converted to Excel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de13cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('output_02.xlsx')\n",
    "\n",
    "# Filter rows where column 0 and 1 have matching values\n",
    "merged_df = df[df[0] == df[1]]\n",
    "\n",
    "# Drop column 1 for matching rows\n",
    "merged_df = merged_df.drop(1, axis=1)\n",
    "\n",
    "# Keep rows with mismatched values as-is\n",
    "df_mismatched = df[df[0] != df[1]]\n",
    "\n",
    "# Combine the merged and mismatched DataFrames\n",
    "df_final = pd.concat([merged_df, df_mismatched])\n",
    "\n",
    "# Save the merged data to a new Excel file\n",
    "df_final.to_excel('output_03.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ec4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load the existing workbook\n",
    "wb = load_workbook(\"output_03.xlsx\")\n",
    "ws = wb.active  # Assumes you're working with the active sheet\n",
    "\n",
    "# Merge cells A2:B2 and A3:B3\n",
    "ws.merge_cells(\"A2:B2\")\n",
    "ws.merge_cells(\"A3:B3\")\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(\"output_03_modified1.xlsx\")  # Saving as a new file to preserve the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4abd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has a line between the merged and unmerged cells\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('output_02.xlsx')\n",
    "\n",
    "# Filter rows where column 0 and 1 have matching values\n",
    "matching_rows = df[df.iloc[:, 0] == df.iloc[:, 1]]\n",
    "\n",
    "# Keep rows with mismatched values as-is\n",
    "df_mismatched = df[df.iloc[:, 0] != df.iloc[:, 1]]\n",
    "\n",
    "# Save the merged data to a new Excel file\n",
    "with pd.ExcelWriter('output_03.xlsx') as writer:\n",
    "    matching_rows.iloc[:, 0:1].to_excel(writer, index=False, header=False)\n",
    "    df_mismatched.to_excel(writer, index=False, header=False, startrow=len(matching_rows)+1)\n",
    "\n",
    "# Load the existing workbook\n",
    "wb = load_workbook(\"output_03.xlsx\")\n",
    "ws = wb.active  \n",
    "\n",
    "# Merge cells A2:B2 and A3:B3 for matching rows\n",
    "for idx in range(2, len(matching_rows) + 2):\n",
    "    ws.merge_cells(f\"A{idx}:B{idx}\")\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(\"output_03_modified2.xlsx\")  # Saving as a new file to preserve the original\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2413a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
